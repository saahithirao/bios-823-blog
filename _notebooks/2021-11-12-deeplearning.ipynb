{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dive into Deep Learning, Classifying images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this blog post is to explain the process of training a deep learning model to classify images (pixels) of insects: beetles, cockroaches, and dragonflies. The neural network (model) will be evaluated on how it classfied the images using Shapley Additive Explanations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to import all of the necessary libraries. This neural network will be using the tensorflow package and specifically, the keras module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import necessary libraries\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# #import tensorflow as tf\n",
    "# #from tensorflow import keras\n",
    "# #import shap\n",
    "\n",
    "# #from PIL import Image\n",
    "# #import urllib\n",
    "# import io \n",
    "\n",
    "# import random\n",
    "# import os\n",
    "\n",
    "# from keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "# from keras.utils import to_categorical\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from tensorflow.keras import Sequential\n",
    "# from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to specify the image size because all the images need to be of the same size in the model and specify three color channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image specifications\n",
    "# width=200\n",
    "# height=200\n",
    "# size=(width,height)\n",
    "# channels = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will create the training data by finding the file paths of each image. The file paths of the images will be added to a training file list and the corresponding image classifiation (type of insect) will be added to a categories list. These lists are appended to a training dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "# trainfiles = []\n",
    "# categories = []\n",
    "\n",
    "# for path in os.listdir(\"insects/train/beetles\"):\n",
    "#     full_path = os.path.join(\"insects/train/beetles\", path)\n",
    "#     if os.path.isfile(full_path):\n",
    "#         trainfiles.append(full_path)\n",
    "#         categories.append(\"beetles\")\n",
    "        \n",
    "# for path in os.listdir(\"insects/train/cockroach\"):\n",
    "#     full_path = os.path.join(\"insects/train/cockroach\", path)\n",
    "#     if os.path.isfile(full_path):\n",
    "#         trainfiles.append(full_path)\n",
    "#         categories.append(\"cockroach\")\n",
    "\n",
    "# for path in os.listdir(\"insects/train/dragonflies\"):\n",
    "#     full_path = os.path.join(\"insects/train/dragonflies\", path)\n",
    "#     if os.path.isfile(full_path):\n",
    "#         trainfiles.append(full_path)\n",
    "#         categories.append(\"dragonflies\")\n",
    "\n",
    "# df_train = pd.DataFrame({\n",
    "#     'filename': trainfiles,\n",
    "#     'category': categories\n",
    "# })        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we will create the testing data. The file paths of the images will be added to a test file list and the corresponding image classifiation (type of insect) will be added to a categories list. These lists are appended to a test dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\n",
    "# testfiles = []\n",
    "# categories = []\n",
    "\n",
    "# for path in os.listdir(\"insects/test/beetles\"):\n",
    "#     full_path = os.path.join(\"insects/test/beetles\", path)\n",
    "#     if os.path.isfile(full_path):\n",
    "#         testfiles.append(full_path)\n",
    "#         categories.append(\"beetles\")\n",
    "        \n",
    "# for path in os.listdir(\"insects/test/cockroach\"):\n",
    "#     full_path = os.path.join(\"insects/test/cockroach\", path)\n",
    "#     if os.path.isfile(full_path):\n",
    "#         testfiles.append(full_path)\n",
    "#         categories.append(\"cockroach\")\n",
    "\n",
    "# for path in os.listdir(\"insects/test/dragonflies\"):\n",
    "#     full_path = os.path.join(\"insects/test/dragonflies\", path)\n",
    "#     if os.path.isfile(full_path):\n",
    "#         testfiles.append(full_path)\n",
    "#         categories.append(\"dragonflies\")\n",
    "        \n",
    "# df_test = pd.DataFrame({\n",
    "#     'filename': testfiles,\n",
    "#     'category': categories\n",
    "# })        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This neural network will use a convolution 2D neural net architecture. We will add layers sequentially and each one has separate biases and weights. The output and shape of each layer is shown below. The loss function is 'categorical_crossentropy' and while training the model, this function will be minimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural net model\n",
    "model=Sequential()\n",
    "model.add(Conv2D(32,(3,3),activation='relu',input_shape=(width,height,channels)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128,(3,3),activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "  optimizer='rmsprop',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data will be split into training and validation sets to be used in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df,validate_df = train_test_split(df_train,test_size=0.2,\n",
    "#   random_state=42)\n",
    "\n",
    "# total_train=train_df.shape[0]\n",
    "# total_validate=df_test.shape[0]\n",
    "# batch_size = 10\n",
    "\n",
    "# train_df = train_df.reset_index(drop=True)\n",
    "# validate_df = validate_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some research, ImageDataGenerator seemed like the most optimal solution to create this image classification model as it can efficiently load images in batches. The output shows the number of images in each data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 815 validated image filenames belonging to 3 classes.\n",
      "Found 204 validated image filenames belonging to 3 classes.\n",
      "Found 180 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# train_datagen = ImageDataGenerator(rotation_range=15,\n",
    "#                                 rescale=1./255,\n",
    "#                                 shear_range=0.1,\n",
    "#                                 zoom_range=0.2,\n",
    "#                                 horizontal_flip=True,\n",
    "#                                 width_shift_range=0.1,\n",
    "#                                 height_shift_range=0.1)\n",
    "\n",
    "# train_generator = train_datagen.flow_from_dataframe(train_df, x_col='filename',y_col='category',\n",
    "#                                                  target_size=size,\n",
    "#                                                  class_mode='categorical',\n",
    "#                                                  batch_size=batch_size)\n",
    "\n",
    "\n",
    "# validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# validation_generator = validation_datagen.flow_from_dataframe(\n",
    "#     validate_df, \n",
    "#     x_col='filename',\n",
    "#     y_col='category',\n",
    "#     target_size=size,\n",
    "#     class_mode='categorical',\n",
    "#     batch_size=batch_size)\n",
    "\n",
    "# test_datagen = ImageDataGenerator(rotation_range=15,\n",
    "#                                 rescale=1./255,\n",
    "#                                 shear_range=0.1,\n",
    "#                                 zoom_range=0.2,\n",
    "#                                 horizontal_flip=True,\n",
    "#                                 width_shift_range=0.1,\n",
    "#                                 height_shift_range=0.1)\n",
    "\n",
    "# test_generator = test_datagen.flow_from_dataframe(df_test,x_col='filename',y_col='category',\n",
    "#                                                  target_size=size,\n",
    "#                                                  class_mode='categorical',\n",
    "#                                                  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will fit the model on the training data and validate it on the validation data. Various epochs and batch sizes were tried and due to the time it took to run the model, 3 and 10 were chosen respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist = model.fit(\n",
    "#     train_generator, \n",
    "#     epochs=3,\n",
    "#     validation_data=validation_generator,\n",
    "#     batch_size=batch_size,\n",
    "#     verbose=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the plot illustrates, the model does not have a high accuracy. A lot of layers were added to the model including batch normalization and dropout layers to make the code run more efficiently. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(1,2,figsize=(12, 4))\n",
    "# for ax, measure in zip(axes, ['loss', 'accuracy']):\n",
    "#     ax.plot(hist.history[measure], label=measure)\n",
    "#     ax.plot(hist.history['val_' + measure], label='val_' + measure)\n",
    "#     ax.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"model1.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test accuracy is about 63%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loss, test_acc = model.evaluate(test_generator)\n",
    "# test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code manipulates the test data frame to be used for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = pd.DataFrame({\n",
    "#     'filename': testfiles\n",
    "# })\n",
    "# nb_samples = test_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code makes predictions from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict(test_generator, steps=np.ceil(nb_samples/batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the prediction of one image by feeding an image of a beetle. The classification was a beetle. Yay!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 beetles\n"
     ]
    }
   ],
   "source": [
    "# results={\n",
    "#     0:'beetles',\n",
    "#     1:'cockroach',\n",
    "#     2:'dragonflies'\n",
    "# }\n",
    "# from PIL import Image\n",
    "# import numpy as np\n",
    "# im=Image.open(\"insects/test/beetles/5556745.jpg\")\n",
    "# im=im.resize(size)\n",
    "# im=np.expand_dims(im,axis=0)\n",
    "# im=np.array(im)\n",
    "# im=im/255\n",
    "# pred=model.predict_classes([im])[0]\n",
    "# print(pred,results[pred])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will describe how well the model performed using shapley additive explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried the following code and several other versions of what is below to convert the training and test sets into numpy arrays to be used in the gradient explainer and for the shapley values. After analyzing the output of the train and test generator (code above), I realized that the data was in batches and I would need to unbatch the data for this to work and plot the images correctly. So, I scratched this idea and skipped to what is shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xtrain = []\n",
    "# ytrain = []\n",
    "\n",
    "# xtrain=np.concatenate([train_generator.next()[0] for i in range(train_generator.__len__())])\n",
    "# ytrain=np.concatenate([train_generator.next()[1] for i in range(train_generator.__len__())])\n",
    "\n",
    "# xtest = []\n",
    "# ytest = []\n",
    "\n",
    "# xtest=np.concatenate([test_generator.next()[0] for i in range(test_generator.__len__())])\n",
    "# ytest=np.concatenate([test_generator.next()[1] for i in range(test_generator.__len__())])\n",
    "\n",
    "# ytest = np.where(ytest == 0, \"beetles\", np.where(ytest == 1, \"cockroach\", \"dragonflies\"))\n",
    "\n",
    "# explainer = shap.GradientExplainer(model, xtrain)\n",
    "# shap_vals = explainer.shap_values(xtest[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code produces the shapley values on the test data using a gradient from the model and background (training data). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explainer = shap.GradientExplainer(model, train_generator[0][0])\n",
    "# shap_vals, index = explainer.shap_values(test_generator[0][0], ranked_outputs = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will create a numpy array to label the images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names = ['beetles', 'cockroach', 'dragonflies']\n",
    "# index_names = np.vectorize(lambda x: names[x])(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will plot the images and see what parts of the images are most important in creating the image classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.image_plot(shap_vals, test_generator[0][0], labels = index_names, show = False)\n",
    "# plt.savefig('shap.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython import display\n",
    "# display.Image(\"./shap.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
